{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=list(dict())\n",
    "all_users=[dict()]\n",
    "\n",
    "def getAllTweetsData(response):\n",
    "    # process users\n",
    "    global data_list\n",
    "    global all_users\n",
    "    users = {}\n",
    "    tweet_user=[]\n",
    "   \n",
    "    all_tweet_list=list()\n",
    "# tweet specific info\n",
    "    \n",
    "    for user in response.includes['users']:\n",
    "    # print(user.username)\n",
    "    # print(user.name)\n",
    "        users[user.id] = f\"{user.name} (@{user.username}) [{user.profile_image_url}]\"\n",
    "        #print(\"User:>>>>>>\",{user})\n",
    "        #all_users.append({user})\n",
    "    # print(dir(inclu))\n",
    " \n",
    "# process media attachment\n",
    "    media = {}\n",
    "    for item in response.includes['media']:\n",
    "        media[item.media_key] = f\"{item.url} - {item.height}x{item.width} - Alt: {item.alt_text}\"\n",
    "        print(media[item.media_key])\n",
    " \n",
    " \n",
    "    tweets = response.data\n",
    " \n",
    "# The expanded tweet offers a lot more data\n",
    "    for tweet in tweets:\n",
    "        data_list.append(dict(tweet))\n",
    "        print('-' * 50)\n",
    "        print(f\"{tweet.id} ({tweet.created_at}) - {users[tweet.author_id]}:\\n {tweet.text} \\n\")\n",
    "        metric = tweet.public_metrics\n",
    "        print(f\"retweets: {metric['retweet_count']} | likes: {metric['like_count']}\")\n",
    "        if tweet.attachments is not None:\n",
    "            for media_key in tweet.attachments['media_keys']:\n",
    "                print(f\"Media attachment: {media[media_key]}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import requests\n",
    "\n",
    "# your bearer token\n",
    "MY_BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAADCKdQEAAAAAp5B7riMWUn8ZPFmeXL%2FFFVSDmp4%3DTpJL8eN4a8HJ35nCs8xd8j2UlprTafjY4iPXTQijKjvSrXBM3D\"\n",
    "# create your client \n",
    "client = tweepy.Client(bearer_token=MY_BEARER_TOKEN)\n",
    "# query to search for tweets\n",
    "query = \"#stressed lang:en -is:retweet\"\n",
    "next_token={}\n",
    "conversationIds=list()\n",
    "# your start and end time for fetching tweets\n",
    "start_time = \"2022-06-02T00:00:00Z\"\n",
    "end_time = \"2022-06-08T00:00:00Z\"\n",
    "user_list=[]\n",
    "#MY_BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAADCKdQEAAAAAp5B7riMWUn8ZPFmeXL%2FFFVSDmp4%3DTpJL8eN4a8HJ35nCs8xd8j2UlprTafjY4iPXTQijKjvSrXBM3D\"\n",
    "# create your client \n",
    "client = tweepy.Client(bearer_token=MY_BEARER_TOKEN)\n",
    "\n",
    "start_time = \"2022-06-03T00:00:00Z\"\n",
    "end_time = \"2022-06-09T00:00:00Z\"\n",
    "next_token={}\n",
    "tweet_fields = [\"created_at\", \"text\", \"source\",\"id\",\"text\",'attachments',\"author_id\",\"in_reply_to_user_id\",\"geo\",\"conversation_id\",\"lang\",\"public_metrics\",\"referenced_tweets\",\"reply_settings\",\"source\",\"referenced_tweets\"]\n",
    "res = []\n",
    "for i in tweet_fields:\n",
    "    if i not in res:\n",
    "        res.append(i)\n",
    "def run_response():\n",
    "    global next_token\n",
    "    response = client.search_recent_tweets(\n",
    "                \"#stressed lang:en -is:retweet\", \n",
    "                start_time=start_time,\n",
    "                end_time=end_time,\n",
    "                max_results=100,\n",
    "                expansions=\"author_id,attachments.media_keys,in_reply_to_user_id,geo.place_id\",\n",
    "                tweet_fields=res,\n",
    "                user_fields=\"created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld\",\n",
    "                next_token=next_token,\n",
    "                media_fields=\"public_metrics,url,height,width,alt_text\")\n",
    "    response.meta.setdefault('next_token',None)\n",
    "    if response.meta is not None:\n",
    "        next_token={response.meta['next_token']}\n",
    "    getAllTweetsData(response)\n",
    "    print('Next token :',next_token)\n",
    "    i=0\n",
    "    for tweet in response.data:\n",
    "    \n",
    "   \n",
    "    # user information for the first tweet\n",
    "        tweet_user=response.includes[\"users\"][i]\n",
    "        all_users.append(dict(tweet_user))\n",
    "        #print(dict(tweet_user),\" <<<User\\n ____________________________________________________________________________\\n\\n\")\n",
    "        #print(dict(tweet),\"\\n\\n\")\n",
    "        data_list.append(dict(tweet))\n",
    "        ++i\n",
    "       \n",
    "        q=tweet.conversation_id\n",
    "        conversationIds.append(q)\n",
    "        #print(\"conversation id : \",q)\n",
    "       \n",
    "        \n",
    "        #curl \"https://api.twitter.com/2/tweets/search/recent$query\" -H \"Authorization: Bearer $BEARER_TOKEN\"\n",
    "# # tweet specific info\n",
    "# print(len(tweets.data))\n",
    "# # user specific info\n",
    "# print(len(tweets.includes[\"users\"]))\n",
    "# # first tweet\n",
    "# i=0\n",
    "# for tweet in tweets.data:\n",
    "    \n",
    "   \n",
    "#     # user information for the first tweet\n",
    "#     tweet_user=tweets.includes[\"users\"][i]\n",
    "#     all_users.append(dict(tweet_user))\n",
    "#     print(dict(tweet_user),\"\\n ____________________________________________________________________________\\n\\n\")\n",
    "#     print(dict(tweet),\"\\n\\n\")\n",
    "#     data_list.append(dict(tweet))\n",
    "#     ++i\n",
    "# #all_tweet_list.append(tweets)\n",
    "# #print('lkjhgfd',len(all_tweet_list))\n",
    "# if tweets.meta is not None:\n",
    "#     next_token={tweets.meta['next_token']}\n",
    "# print(\"next token \",next_token)\n",
    "# j=0\n",
    "\n",
    "    #run_response()\n",
    "   \n",
    "\n",
    "#    print(len(tweets.data))\n",
    "#     # user specific info\n",
    "#    print(len(tweets.includes[\"users\"]))\n",
    "#     # first tweet\n",
    "#    i=0\n",
    "#    for tweet in tweets.data:\n",
    "        \n",
    "    \n",
    "#         # user information for the first tweet\n",
    "#         tweet_user = tweets.includes[\"users\"][i]\n",
    "#         user_dict=dict(tweet_user)\n",
    "#         if user_dict!={}:\n",
    "#             all_users.append(user_dict)\n",
    "#         print(user_dict,\"\\n ____________________________________________________________________________\\n\\n\")\n",
    "#         print(dict(tweet),\"\\n\\n\")\n",
    "#         data_list.append(dict(tweet))\n",
    "#         ++i\n",
    "       \n",
    "   \n",
    "\n",
    "#    #all_tweet_list.append(tweets)\n",
    "#    if 'next_token' in tweets.meta :\n",
    "#         next_token={tweets.meta['next_token']} or {}\n",
    "\n",
    "#    print(\"next token \",next_token)\n",
    "#    print(\"number of pages: \",len(all_tweet_list))\n",
    "\n",
    "\n",
    "# for found_tweet in all_tweet_list:\n",
    "#     data_list.append(found_tweet.data)\n",
    "# # print(len(tweets.data))\n",
    "# # user specific info\n",
    "#     print('users length',len(found_tweet.includes[\"users\"]))\n",
    "#     user_list.append(found_tweet.includes[\"users\"])\n",
    "# # first tweet\n",
    "# j=0\n",
    "# for our_users in  user_list:\n",
    "   \n",
    "#     for user in our_users:\n",
    "#          print(user)\n",
    "#     print(\"\\n___________________________________________________________\\n\")\n",
    "#      # user information for the first tweet\n",
    "#      #for user in our_users:\n",
    "         \n",
    "#         # tweet_user = user[j]\n",
    "#         # print(dict(tweet_user),\"\\n ____________________________________________________________________________\\n\\n\")\n",
    "#         # #print(dict(tweet),\"\\n\\n\")\n",
    "    \n",
    "# i=0\n",
    "# for tweet in data_list:\n",
    "    \n",
    "   \n",
    "#     # user information for the first tweet\n",
    "#     tweet_user = tweets.includes[\"users\"][i]\n",
    "#     print(dict(tweet_user),\"\\n ____________________________________________________________________________\\n\\n\")\n",
    "#     print(tweet,\"\\n\\n\")\n",
    "#     ++i\n",
    "# # first_tweet = tweets.data[0]\n",
    "# # dict(first_tweet)\n",
    "# print(len(all_users))\n",
    "# print(\"___________________________________________________________________________________________________________________________________________________\")\n",
    "# print(\"data list\", len(data_list))\n",
    "\n",
    "for i in range(0,100):\n",
    "    run_response()\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving the conversation by conversation ids\n",
    "max=100\t\t# limits differ across endpoints\n",
    "#k=0\n",
    "for q in conversationIds:\n",
    "\n",
    "    # if k>=20:\n",
    "    #     break\n",
    "    query=\"conversation_id:\"+str(q)\n",
    "    response_data=client.search_recent_tweets(query=query,max_results=max)\n",
    "    print(response_data)\n",
    "    print(\"...................................................................................................................\")\n",
    "    #++k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user size 3\n",
      "data size :  17492\n",
      "{'name': 'David Kowalski', 'location': 'Cleveland, OH', 'verified': False, 'public_metrics': {'followers_count': 327, 'following_count': 1554, 'tweet_count': 7538, 'listed_count': 3}, 'url': '', 'profile_image_url': 'https://pbs.twimg.com/profile_images/1019219453513478147/qCURc4MR_normal.jpg', 'created_at': datetime.datetime(2012, 2, 5, 0, 45, 42, tzinfo=datetime.timezone.utc), 'username': 'DavidJKowalski', 'id': 483425478, 'description': 'Hakuna Matata, thoughts and opinions are my own. OH politics, UNION Proud, CLE Sports', 'protected': False}\n",
      "{'name': 'Udaya Kumar', 'verified': False, 'public_metrics': {'followers_count': 7, 'following_count': 155, 'tweet_count': 2289, 'listed_count': 0}, 'url': '', 'profile_image_url': 'https://pbs.twimg.com/profile_images/1356428789492838400/g74ijsu4_normal.jpg', 'created_at': datetime.datetime(2016, 4, 29, 5, 24, 7, tzinfo=datetime.timezone.utc), 'username': 'redefinethearth', 'id': 725918563228221440, 'description': 'Common man of India', 'protected': False, 'pinned_tweet_id': 1487218279105974272}\n",
      "{'name': 'ChillFrogCBD', 'profile_image_url': 'https://pbs.twimg.com/profile_images/1470907458201665539/epAyPDCn_normal.jpg', 'url': 'https://t.co/pq7yOxwRqr', 'id': 1351634330783649793, 'created_at': datetime.datetime(2021, 1, 19, 20, 55, 38, tzinfo=datetime.timezone.utc), 'location': 'Southern California', 'protected': False, 'entities': {'url': {'urls': [{'start': 0, 'end': 23, 'url': 'https://t.co/pq7yOxwRqr', 'expanded_url': 'https://linktr.ee/ChillFrogCBD', 'display_url': 'linktr.ee/ChillFrogCBD'}]}, 'description': {'hashtags': [{'start': 54, 'end': 68, 'tag': 'FindYourChill'}]}}, 'username': 'FrogCbd', 'public_metrics': {'followers_count': 29, 'following_count': 16, 'tweet_count': 56, 'listed_count': 0}, 'verified': False, 'description': 'Premium CBD Products. We are all about helping you to #FindYourChill in a stressful world. Come check out our pond! üê∏'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>verified</th>\n",
       "      <th>description</th>\n",
       "      <th>profile_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-08 23:21:52+00:00</td>\n",
       "      <td>If you ordered something in March for a weddin...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>David Kowalski</td>\n",
       "      <td>DavidJKowalski</td>\n",
       "      <td>Cleveland, OH</td>\n",
       "      <td>False</td>\n",
       "      <td>Hakuna Matata, thoughts and opinions are my ow...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/101921945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-08 22:21:22+00:00</td>\n",
       "      <td>i am so #stressed</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Udaya Kumar</td>\n",
       "      <td>redefinethearth</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>Common man of India</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/135642878...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-08 22:11:05+00:00</td>\n",
       "      <td>It's lurking in your brain and body.\\n\\nHave y...</td>\n",
       "      <td>SocialChamp IO</td>\n",
       "      <td>ChillFrogCBD</td>\n",
       "      <td>FrogCbd</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>False</td>\n",
       "      <td>Premium CBD Products. We are all about helping...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/147090745...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at  \\\n",
       "0 2022-06-08 23:21:52+00:00   \n",
       "1 2022-06-08 22:21:22+00:00   \n",
       "2 2022-06-08 22:11:05+00:00   \n",
       "\n",
       "                                                text              source  \\\n",
       "0  If you ordered something in March for a weddin...  Twitter for iPhone   \n",
       "1                                  i am so #stressed  Twitter for iPhone   \n",
       "2  It's lurking in your brain and body.\\n\\nHave y...     SocialChamp IO    \n",
       "\n",
       "             name         username             location  verified  \\\n",
       "0  David Kowalski   DavidJKowalski        Cleveland, OH     False   \n",
       "1     Udaya Kumar  redefinethearth                          False   \n",
       "2    ChillFrogCBD          FrogCbd  Southern California     False   \n",
       "\n",
       "                                         description  \\\n",
       "0  Hakuna Matata, thoughts and opinions are my ow...   \n",
       "1                                Common man of India   \n",
       "2  Premium CBD Products. We are all about helping...   \n",
       "\n",
       "                                   profile_image_url  \n",
       "0  https://pbs.twimg.com/profile_images/101921945...  \n",
       "1  https://pbs.twimg.com/profile_images/135642878...  \n",
       "2  https://pbs.twimg.com/profile_images/147090745...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# create a list of records\n",
    "tweet_info_ls = []\n",
    "new_user_list=list(dict())\n",
    "for user_data in all_users:\n",
    "    #print(user_data)\n",
    "    if user_data!={} and not new_user_list.__contains__(user_data) :\n",
    "        new_user_list.append(user_data)\n",
    "print(\"user size\",len(new_user_list))\n",
    "print(\"data size : \",len(data_list))\n",
    "# iterate over each tweet and corresponding user details\n",
    "for tweet, user in zip(data_list, new_user_list):\n",
    "    print(user)\n",
    "    user.setdefault('location', \"\")\n",
    "    # user.setdefault('verified', \"\")\n",
    "    # user.setdefault('description',\"\")\n",
    "    # print(len(user))\n",
    "    \n",
    "    #print(tweet['created_at'])\n",
    "   \n",
    "        \n",
    "    \n",
    "    tweet_info = {\n",
    "        'created_at': tweet['created_at'],\n",
    "        'text': tweet['text'],\n",
    "        'source': tweet['source'],\n",
    "        'name': user['name'],\n",
    "        'username': user['username'],\n",
    "        'location': user['location'],\n",
    "        'verified': user['verified'],\n",
    "        'description': user['description'],\n",
    "        'profile_image_url':user['profile_image_url']\n",
    "    }\n",
    "    tweet_info_ls.append(tweet_info)\n",
    "\n",
    "# create dataframe from the extracted records\n",
    "tweets_df = pd.DataFrame(tweet_info_ls)\n",
    "# display the dataframe\n",
    "tweets_df.head(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "tweets_df.to_csv(r'twitterData.csv',index = False, header=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
